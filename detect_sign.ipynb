{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import mediapipe as mp\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "model = load_model('asl_cnn_model.h5')\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "label_list = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', \n",
    "              'n', 'nothing', 'o', 'p', 'q', 'r', 's', 'space', 't', 'u', 'v', \n",
    "              'w', 'x', 'y', 'z']\n",
    "\n",
    "print(\"Label list loaded:\", label_list)\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def detect_sign():\n",
    "    with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.8) as hands:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break  \n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_rgb = cv2.flip(frame_rgb, 1)  \n",
    "            frame_rgb.flags.writeable = False\n",
    "            results = hands.process(frame_rgb)\n",
    "            frame_rgb.flags.writeable = True\n",
    "            frame_rgb = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            if results.multi_hand_landmarks:\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    mp_drawing.draw_landmarks(frame_rgb, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                    data_aux = []\n",
    "                    for landmark in hand_landmarks.landmark:\n",
    "                        data_aux.append(landmark.x)\n",
    "                        data_aux.append(landmark.y)\n",
    "\n",
    "                    if len(data_aux) == 42:  \n",
    "                        input_data = np.array(data_aux).reshape(1, 42, 1)\n",
    "                        prediction = model.predict(input_data)\n",
    "                        predicted_label_index = np.argmax(prediction, axis=1)[0]\n",
    "                        if predicted_label_index < len(label_list):\n",
    "                            sign_name = label_list[predicted_label_index]\n",
    "                        else:\n",
    "                            sign_name = \"Unknown Sign\"  \n",
    "                        cv2.putText(frame_rgb, sign_name, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "            cv2.imshow('ASL Detection', frame_rgb)\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    detect_sign()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
